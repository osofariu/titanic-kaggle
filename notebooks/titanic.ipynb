{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "t_train_orig = pd.read_csv(\"../data/raw/train.csv\")\n",
    "t_train_orig.name = \"Titanic Training Set\"\n",
    "t_test_orig = pd.read_csv(\"../data/raw/test.csv\")\n",
    "t_test_orig.name = \"Titanic Test Set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Women were much more likely to survive than men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x137e60b50>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEhCAYAAACEF+AUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAXH0lEQVR4nO3df5BdZZ3n8ffXTiSBKNEksDEd6bBGDDFJQ9oYltXKgMsPhwm6BWlwJ2aRqig/hrhM7S7jaBlrhxp0cBxEC8kuDlGBJMK4ZLOuI0bBHVHGboiBJFJEBNPZYDoB4oAEAnz3j3sSO7/6R9LdN3n6/arquuc85znnfm+n+9Mnz33OuZGZSJLK8oZ6FyBJ6n+GuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgXoV7hExOiLujohfRsSGiDgjIt4aEfdFxBPV41uqvhERX46IjRGxNiJOH9iXIEnaV2/P3G8CvpeZ7wJmABuA64DVmTkZWF2tA5wPTK6+FgK39GvFkqQeRU8XMUXE8cAa4OTs0jkiHgfmZOaWiBgP3J+Zp0TErdXyXfv2O9hzjB07Npuamg7/1UjSENLe3r4tM8cdaNuwXuw/CegE/j4iZgDtwCLgxC6B/QxwYrU8AdjUZf+Oqu2g4d7U1ERbW1svSpEk7RYRTx9sW2+GZYYBpwO3ZOZpwIv8YQgGgOqMvk/3MYiIhRHRFhFtnZ2dfdlVktSD3oR7B9CRmQ9V63dTC/vfVsMxVI9bq+2bgYld9m+s2vaSmUsysyUzW8aNO+D/KiRJh6jHcM/MZ4BNEXFK1XQ2sB5YCSyo2hYA91bLK4GPVrNmZgM7uhtvlyT1v96MuQP8GXBHRLwReBK4jNofhhURcTnwNDCv6vtd4IPARuD3Vd8+27VrFx0dHezcufNQdh/SRowYQWNjI8OHD693KZLqpFfhnplrgJYDbDr7AH0TuOow66Kjo4M3velNNDU1ERGHe7ghIzPZvn07HR0dTJo0qd7lSKqTI/YK1Z07dzJmzBiDvY8igjFjxvg/HmmIO2LDHTDYD5HfN0lHdLgfCa6//nqmTp3K9OnTaW5u5qGHHup5px6sXLmSG264oR+qg1GjRvXLcSSVpbdvqNZd03X/u1+P99QNf9xjn5/+9KesWrWKhx9+mGOOOYZt27bxyiuv9Or4r776KsOGHfjbO3fuXObOnduneqVuLT6+3hWUZfGOeldw2Dxz78aWLVsYO3YsxxxzDABjx47lbW97G01NTWzbtg2AtrY25syZA8DixYuZP38+Z555JvPnz2f27NmsW7duz/HmzJlDW1sbt99+O1dffTU7duzgpJNO4vXXXwfgxRdfZOLEiezatYtf/epXnHfeecycOZP3ve99/PKXvwTg17/+NWeccQbTpk3j05/+9CB+NyQdTQz3bpxzzjls2rSJd77znVx55ZU88MADPe6zfv16fvCDH3DXXXfR2trKihUrgNofii1bttDS8odJR8cffzzNzc17jrtq1SrOPfdchg8fzsKFC7n55ptpb2/nxhtv5MorrwRg0aJFXHHFFTz66KOMHz9+AF61pBIY7t0YNWoU7e3tLFmyhHHjxtHa2srtt9/e7T5z585l5MiRAMybN4+7774bgBUrVnDRRRft17+1tZXly5cDsGzZMlpbW3nhhRd48MEHufjii2lububjH/84W7bUrgP7yU9+wqWXXgrA/Pnz++ulSirMUTPmXi8NDQ3MmTOHOXPmMG3aNJYuXcqwYcP2DKXsO+XwuOOO27M8YcIExowZw9q1a1m+fDlf+9rX9jv+3Llz+dSnPsWzzz5Le3s7Z511Fi+++CKjR49mzZo1B6zJ2TCSeuKZezcef/xxnnjiiT3ra9as4aSTTqKpqYn29nYA7rnnnm6P0drayhe+8AV27NjB9OnT99s+atQo3vOe97Bo0SIuuOACGhoaePOb38ykSZP49re/DdQuTPrFL34BwJlnnsmyZcsAuOOOO/rldUoqj+HejRdeeIEFCxZw6qmnMn36dNavX8/ixYv57Gc/y6JFi2hpaaGhoaHbY1x00UUsW7aMefPmHbRPa2sr3/rWt2htbd3Tdscdd3DbbbcxY8YMpk6dyr331m7dc9NNN/HVr36VadOmsXnzfvdjkySgFx/WMRhaWlpy3/u5b9iwgSlTptSpoqOf378hxqmQ/esomQoZEe2ZeaBbw3jmLkklMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuHejoaGB5uZmpk6dyowZM/jiF7+458rUtrY2rrnmmj4db/eNwyRpoB09tx/o73m8vZjHOnLkyD23ANi6dSsf+chH+N3vfsfnPvc5Wlpa9roJmCQdSTxz76UTTjiBJUuW8JWvfIXM5P777+eCCy4Aarfq/djHPsasWbM47bTT9lxN+tJLL3HJJZcwZcoUPvzhD/PSSy/V8yVIGkKOnjP3I8DJJ5/Ma6+9xtatW/dqv/766znrrLP4+te/zvPPP8+sWbP4wAc+wK233sqxxx7Lhg0bWLt2LaeffnqdKpc01Bju/eD73/8+K1eu5MYbbwRqd4r8zW9+w49//OM94/LTp08/4I3DJGkgGO598OSTT9LQ0MAJJ5zAhg0b9rRnJvfccw+nnHJKHauTpD9wzL2XOjs7+cQnPsHVV1+93/3Uzz33XG6++WZ234TtkUceAeD9738/d955JwCPPfYYa9euHdyiJQ1Znrl346WXXqK5uZldu3YxbNgw5s+fz7XXXrtfv8985jN88pOfZPr06bz++utMmjSJVatWccUVV3DZZZcxZcoUpkyZwsyZM+vwKiQNRUdPuNfhFpyvvfbaQbft/nQmqE2ZvPXWW/frM3LkyD0frCFJg8lhGUkqUK/CPSKeiohHI2JNRLRVbW+NiPsi4onq8S1Ve0TElyNiY0SsjQjn/0nSIOvLmfsfZWZzl0/9uA5YnZmTgdXVOsD5wOTqayFwS38VK0nqncMZlrkQWFotLwU+1KX9G1nzM2B0RIw/lCc4Ej4C8Gjk901Sb8M9ge9HRHtELKzaTszMLdXyM8CJ1fIEYFOXfTuqtj4ZMWIE27dvN6j6KDPZvn07I0aMqHcpkuqot7Nl/m1mbo6IE4D7IuKXXTdmZkZEn1K4+iOxEODtb3/7ftsbGxvp6Oigs7OzL4cVtT+MjY2N9S5DUh31Ktwzc3P1uDUivgPMAn4bEeMzc0s17LL7hiubgYlddm+s2vY95hJgCUBLS8t+fxiGDx/OpEmT+vJaJEmVHodlIuK4iHjT7mXgHOAxYCWwoOq2ALi3Wl4JfLSaNTMb2NFl+EaSNAh6c+Z+IvCd6pL7YcCdmfm9iPg5sCIiLgeeBuZV/b8LfBDYCPweuKzfq5YkdavHcM/MJ4EZB2jfDpx9gPYEruqX6iRJh8QrVCWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAvU63COiISIeiYhV1fqkiHgoIjZGxPKIeGPVfky1vrHa3jQwpUuSDqYvZ+6LgA1d1j8PfCkz3wE8B1xetV8OPFe1f6nqJ0kaRL0K94hoBP4Y+B/VegBnAXdXXZYCH6qWL6zWqbafXfWXJA2S3p65/x3wX4DXq/UxwPOZ+Wq13gFMqJYnAJsAqu07qv6SpEHSY7hHxAXA1sxs788njoiFEdEWEW2dnZ39eWhJGvJ6c+Z+JjA3Ip4CllEbjrkJGB0Rw6o+jcDmankzMBGg2n48sH3fg2bmksxsycyWcePGHdaLkCTtrcdwz8y/yMzGzGwCLgF+mJn/AfgRcFHVbQFwb7W8slqn2v7DzMx+rVqS1K3Dmef+X4FrI2IjtTH126r224AxVfu1wHWHV6Ikqa+G9dzlDzLzfuD+avlJYNYB+uwELu6H2iRJh8grVCWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBVoWL0LOKosPr7eFZRl8Y56VyAVq8cz94gYERH/HBG/iIh1EfG5qn1SRDwUERsjYnlEvLFqP6Za31htbxrYlyBJ2ldvhmVeBs7KzBlAM3BeRMwGPg98KTPfATwHXF71vxx4rmr/UtVPkjSIegz3rHmhWh1efSVwFnB31b4U+FC1fGG1TrX97IiIfqtYktSjXr2hGhENEbEG2ArcB/wKeD4zX626dAATquUJwCaAavsOYEx/Fi1J6l6vwj0zX8vMZqARmAW863CfOCIWRkRbRLR1dnYe7uEkSV30aSpkZj4P/Ag4AxgdEbtn2zQCm6vlzcBEgGr78cD2AxxrSWa2ZGbLuHHjDrF8SdKB9Ga2zLiIGF0tjwT+HbCBWshfVHVbANxbLa+s1qm2/zAzsz+LliR1rzfz3McDSyOigdofgxWZuSoi1gPLIuKvgEeA26r+twHfjIiNwLPAJQNQtySpGz2Ge2auBU47QPuT1Mbf923fCVzcL9VJkg6Jtx+QpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCtSbD8hWpWnnnfUuoShP1bsAqWCeuUtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVKAewz0iJkbEjyJifUSsi4hFVftbI+K+iHiienxL1R4R8eWI2BgRayPi9IF+EZKkvfXmzP1V4M8z81RgNnBVRJwKXAeszszJwOpqHeB8YHL1tRC4pd+rliR1q8dwz8wtmflwtfwvwAZgAnAhsLTqthT4ULV8IfCNrPkZMDoixvd75ZKkg+rTmHtENAGnAQ8BJ2bmlmrTM8CJ1fIEYFOX3TqqNknSIOl1uEfEKOAe4JOZ+buu2zIzgezLE0fEwohoi4i2zs7OvuwqSepBr8I9IoZTC/Y7MvMfqubf7h5uqR63Vu2bgYlddm+s2vaSmUsysyUzW8aNG3eo9UuSDqA3s2UCuA3YkJl/22XTSmBBtbwAuLdL+0erWTOzgR1dhm8kSYOgN7f8PROYDzwaEWuqtk8BNwArIuJy4GlgXrXtu8AHgY3A74HL+rViSVKPegz3zPwnIA6y+ewD9E/gqsOsS5J0GLxCVZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kq0LCeOkTE14ELgK2Z+e6q7a3AcqAJeAqYl5nPRUQANwEfBH4P/MfMfHhgSpe0W9POO+tdQlGeqncB/aA3Z+63A+ft03YdsDozJwOrq3WA84HJ1ddC4Jb+KVOS1Bc9hntm/hh4dp/mC4Gl1fJS4ENd2r+RNT8DRkfE+P4qVpLUO4c65n5iZm6plp8BTqyWJwCbuvTrqNr2ExELI6ItIto6OzsPsQxJ0oEc9huqmZlAHsJ+SzKzJTNbxo0bd7hlSJK6ONRw/+3u4ZbqcWvVvhmY2KVfY9UmSRpEhxruK4EF1fIC4N4u7R+NmtnAji7DN5KkQdKbqZB3AXOAsRHRAXwWuAFYERGXA08D86ru36U2DXIjtamQlw1AzZKkHvQY7pl56UE2nX2AvglcdbhFSZIOj1eoSlKBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFGpBwj4jzIuLxiNgYEdcNxHNIkg6u38M9IhqArwLnA6cCl0bEqf39PJKkgxuIM/dZwMbMfDIzXwGWARcOwPNIkg5i2AAccwKwqct6B/DefTtFxEJgYbX6QkQ8PgC1DFVjgW31LqIn8fl6V6A68Gezf510sA0DEe69kplLgCX1ev6SRURbZrbUuw5pX/5sDp6BGJbZDEzsst5YtUmSBslAhPvPgckRMSki3ghcAqwcgOeRJB1Evw/LZOarEXE18I9AA/D1zFzX38+jbjncpSOVP5uDJDKz3jVIkvqZV6hKUoEMd0kqkOEuSQUy3CUNuIgYGRGn1LuOocRwL0BEvDMiVkfEY9X69Ij4dL3rkgAi4k+ANcD3qvXmiHB69AAz3Mvw34G/AHYBZOZaatcXSEeCxdTuOfU8QGauASbVs6ChwHAvw7GZ+c/7tL1al0qk/e3KzB37tDkHe4DV7d4y6lfbIuJfU/3CRMRFwJb6liTtsS4iPgI0RMRk4BrgwTrXVDwvYipARJxM7cq/fwM8B/wa+NPMfKqedUkAEXEs8JfAOUBQu3r9v2XmzroWVjjDvSARcRzwhsz8l3rXIqm+DPejWERc2932zPzbwapF2ldE/C+6GVvPzLmDWM6Q45j70e1N9S5A6saN9S5gKPPMXZIK5Jl7ASJiBHA5MBUYsbs9Mz9Wt6KkSjVD5q+BU9n75/PkuhU1BDjPvQzfBP4VcC7wALVPv/JNVR0p/h64hdq1F38EfAP4Vl0rGgIclilARDySmadFxNrMnB4Rw4H/m5mz612bFBHtmTkzIh7NzGld2+pdW8kclinDrurx+Yh4N/AMcEId65G6ejki3gA8UX1K22ZgVJ1rKp7DMmVYEhFvAT5D7fNq1wNfqG9J0h6LgGOpXZk6E/hT4KN1rWgIcFhG0oCKiBZqV6ieBAyvmjMzp9evqvIZ7gWIiNHUzoSa6DLUlpnX1KsmabeIeBz4z8CjwOu72zPz6boVNQQ45l6G7wI/Y59fHukI0ZmZ3r99kHnmXoCIeDgzT693HdKBRMTZwKXAauDl3e2Z+Q91K2oIMNwLEBH/CXgBWMXevzzP1q0oqRIR3wLeBazjD/+zTC+yG1iGewEi4irgemqfdLP7HzS9AlBHgoh4PDP9/NRB5ph7Gf4ceEdmbqt3IdIBPBgRp2bm+noXMpQY7mXYCPy+3kVIBzEbWBMRv6Y2bBg4FXLAGe5leJHaL8+P2HvM3amQOhKcV+8ChiLDvQz/s/qSjjjOZ68P31AtRESMBN6emY/XuxZJ9ee9ZQoQEX8CrAG+V603R4QXjUhDmOFehsXALGpTIcnMNYDTIKUhzHAvw67M3LFPm7chkIYw31Atw7qI+AjQUH2k2TXAg3WuSVIdeeZ+FIuIb1aLv6L2+akvA3cBvwM+Wa+6JNWfs2WOYhGxHvgA8H+ofTblXry3jDR0OSxzdPsatTvtnQy0dWkPaveY8U1VaYjyzL0AEXFLZl5R7zokHTkMd0kqkG+oSlKBDHdJKpDhriEvIv4yItZFxNqIWBMR7613TdLhcraMhrSIOAO4ADg9M1+OiLHAG+tclnTYPHPXUDce2JaZLwNk5rbM/H8RMTMiHoiI9oj4x4gYHxHDIuLnETEHICL+OiKur2fx0sE4W0ZDWkSMAv4JOBb4AbCc2q0bHgAuzMzOiGgFzs3Mj0XEVOBu4M+AvwHem5mv1Kd66eAcltGQlpkvRMRM4H3UrvJdDvwV8G7gvogAaAC2VP3XVbd9WAWcYbDrSGW4a8jLzNeA+4H7I+JR4CpgXWaecZBdplG7vfIJg1Oh1HeOuWtIi4hTqjtp7tYMbADGVW+2EhHDq+EYIuLfA28F3g/cHBGjB7tmqTccc9eQVg3J3AyMBl4FNgILgUbgy8Dx1P6H+3fAd6iNx5+dmZsi4hpgZmYuqEftUncMd0kqkMMyklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAL9f2P7RqCbvyICAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_train_orig['Died']= t_train_orig['Survived'].map(lambda survived: 0 if survived == 1 else 1)\n",
    "t_train_orig.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', stacked='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher fare improves chance of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x137e72c90>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = t_train_orig\n",
    "fare_survived =t[t['Survived'] == 1]['Fare'] \n",
    "fare_died = t[t['Survived'] == 0]['Fare'] \n",
    "plt.hist([fare_survived, fare_died], stacked=True, color = ['g', 'r'], \n",
    "         bins = 25, label=['Survived', 'Died'])\n",
    "plt.xlabel('fare')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class also improves chance of survival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x136530f90>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_train_orig.groupby('Pclass').agg('sum')[['Survived', 'Died']].plot(kind='bar', stacked='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for columns with missing values and fill them\n",
    "Fill NAs in the training data for age, cabin, and embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Training Set\n",
      "Age column missing values: 177\n",
      "Cabin column missing values: 687\n",
      "Embarked column missing values: 2\n",
      "\n",
      "\n",
      "Titanic Test Set\n",
      "Age column missing values: 86\n",
      "Fare column missing values: 1\n",
      "Cabin column missing values: 327\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist(): \n",
    "        if df[col].isnull().sum() > 0:\n",
    "            print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "\n",
    "dfs = [t_train_orig, t_test_orig]\n",
    "\n",
    "for df in dfs:\n",
    "    print('{}'.format(df.name))\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      S\n",
       "1      C\n",
       "2      S\n",
       "3      S\n",
       "4      S\n",
       "      ..\n",
       "886    S\n",
       "887    S\n",
       "888    S\n",
       "889    C\n",
       "890    Q\n",
       "Name: Embarked, Length: 891, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train = t_train_orig\n",
    "median_ages = t_train.groupby('Pclass').median()\n",
    "t_train['Age'] = t_train.apply(lambda row: median_ages['Age'][row['Pclass']] if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "t_train['Cabin'].fillna('U')\n",
    "import operator\n",
    "embarked_group_counts = sorted(t_train.groupby('Embarked')['PassengerId'].count().items(), key=operator.itemgetter(1), reverse=True)\n",
    "# fillNA for Embarked with the most common port code\n",
    "t_train['Embarked'].fillna(embarked_group_counts[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Robins, Mrs. Alexander A (Grace Charity Laury)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 3337</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Risien, Mr. Samuel Beard</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364498</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pengelly, Mr. Frederick William</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28665</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>609</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Laroche, Mrs. Joseph (Juliette Marie Louise La...</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Seward, Mr. Frederic Kimber</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113794</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sivola, Mr. Antti Wilhelm</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101280</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldenberg, Mrs. Samuel L (Edwiga Grabowska)</td>\n",
       "      <td>female</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17453</td>\n",
       "      <td>89.1042</td>\n",
       "      <td>C92</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "132          133         0       3   \n",
       "870          871         0       3   \n",
       "538          539         0       3   \n",
       "238          239         0       2   \n",
       "608          609         1       2   \n",
       "447          448         1       1   \n",
       "173          174         0       3   \n",
       "849          850         1       1   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "132     Robins, Mrs. Alexander A (Grace Charity Laury)  female  47.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "538                           Risien, Mr. Samuel Beard    male  24.0      0   \n",
       "238                    Pengelly, Mr. Frederick William    male  19.0      0   \n",
       "608  Laroche, Mrs. Joseph (Juliette Marie Louise La...  female  22.0      1   \n",
       "447                        Seward, Mr. Frederic Kimber    male  34.0      0   \n",
       "173                          Sivola, Mr. Antti Wilhelm    male  21.0      0   \n",
       "849       Goldenberg, Mrs. Samuel L (Edwiga Grabowska)  female  37.0      1   \n",
       "\n",
       "     Parch             Ticket     Fare Cabin Embarked  Died  \n",
       "132      0          A/5. 3337  14.5000   NaN        S     1  \n",
       "870      0             349248   7.8958   NaN        S     1  \n",
       "538      0             364498  14.5000   NaN        S     1  \n",
       "238      0              28665  10.5000   NaN        S     1  \n",
       "608      2      SC/Paris 2123  41.5792   NaN        C     0  \n",
       "447      0             113794  26.5500   NaN        S     0  \n",
       "173      0  STON/O 2. 3101280   7.9250   NaN        S     1  \n",
       "849      0              17453  89.1042   C92        C     0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train_orig.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature exploration\n",
    "\n",
    "Here are some initial ideas:\n",
    "* Pclass (1 > 2 > 3)\n",
    "* Fare ($$ > $)\n",
    "* Sex (female > male)\n",
    "* CabinPresent (1 > 0)\n",
    "* Is child over 12 (1 > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FareAdjusted</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SexNumeric</th>\n",
       "      <th>TitleNumeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>14.4000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>7.7750</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>52.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>7.2292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>39.6875</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>18.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8.6542</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FareAdjusted  Pclass  SexNumeric  TitleNumeric\n",
       "423       14.4000       3           1             4\n",
       "878        7.8958       3           0             1\n",
       "457       51.8625       1           1             4\n",
       "246        7.7750       3           1             6\n",
       "87         8.0500       3           0             1\n",
       "467       26.5500       1           0             1\n",
       "35        52.0000       1           0             1\n",
       "296        7.2292       3           0             1\n",
       "686       39.6875       3           0             1\n",
       "38        18.0000       3           1             6\n",
       "724       53.1000       1           0             1\n",
       "103        8.6542       3           0             1"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn import preprocessing\n",
    "\n",
    "t_train = t_train_orig\n",
    "\n",
    "# sex to numeric\n",
    "t_train['SexNumeric'] = np.where(t_train['Sex'] == \"male\", 0, 1)\n",
    "\n",
    "# fill in missing fare with median fare for passengers in the same class\n",
    "median_fares = t_train.groupby('Pclass')['Fare'].median()\n",
    "def fare_for_class(row):\n",
    "    return median_fares[row['Pclass']] if row['Fare'] == 0 else row['Fare']\n",
    "t_train['FareAdjusted'] = t_train.apply(fare_for_class,axis=1)\n",
    "\n",
    "# TODO: update AgeAdjusted to take into account title to refine the likely age, so that a child with\n",
    "# missing age doesn't get classified as an adult.. a male child should be much more likely to survive\n",
    "# so that should help\n",
    "\n",
    "# extract titles\n",
    "#get_index = lambda x, xs: [i for (y, i) in zip(xs, range(len(xs))) if x == y][0]\n",
    "\n",
    "t_train['Title'] = t_train_orig['Name'].map(lambda name: [title for title in name.split(' ') if '.' in title][0])\n",
    "#all_titles = t_train['Title'].unique()\n",
    "titles_esteemed_first = {\n",
    "    'Countess.': 17,\n",
    "    'Lady.': 16,\n",
    "    'Rev.': 15,\n",
    "    'Jonkheer.': 14,\n",
    "    'Master.': 13,\n",
    "    'Major.' : 12,\n",
    "    'Don.': 11,\n",
    "    'Dr.' : 10,\n",
    "    'Col.': 9,\n",
    "    'Capt.': 8,\n",
    "    'Mlle.': 7,\n",
    "    'Miss.': 6,\n",
    "    'Ms.': 5,\n",
    "    'Mrs.': 4,\n",
    "    'Mme.': 3,\n",
    "    'Sir.': 2,\n",
    "    'Mr.': 1\n",
    "}\n",
    "\n",
    "t_train['TitleNumeric'] = t_train['Title'].map(lambda title: titles_esteemed_first[title])\n",
    "\n",
    "feature_cols = ['FareAdjusted', 'Pclass', 'SexNumeric', 'TitleNumeric']\n",
    "t_train[feature_cols].sample(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8208955223880597\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "X_dt = t_train[feature_cols]\n",
    "y_dt = t_train.Survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dt, y_dt, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "t_train['Deck'] = \\\n",
    "    t_train['Cabin'].map(lambda cabin: cabin[0] if (type(cabin) == str) else \"U\")\n",
    "\n",
    "# simply having s cabin assigned increases chances of survival\n",
    "t_train['CabinGoodNumeric'] = \\\n",
    "t_train['Deck'].map(lambda letter: 1 if (letter in \"BDEG\") else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlate deck with survival rate for assigned cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x134347110>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlate deck with survival rate for assigned cabins\n",
    "import string\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, False, figsize=(20,5))\n",
    "t_train_orig[t_train_orig['Deck'] != 'U'].groupby('Deck').agg('sum')[['Survived', 'Died']].plot(kind='bar', stacked='true', ax=ax2)\n",
    "t_train_orig.groupby('CabinGoodNumeric').agg('sum')[['Survived', 'Died']].plot(kind='bar', stacked='true', ax=ax1)\n",
    "\n",
    "# CabinGoodNumeric doesn't yet seem to inprove things.. can it be made to be useful?\n",
    "# why is it not a very important feature according to random forrest.. is it because most people don't have a cabin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Correlation Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Survived</td>\n",
       "      <td>SexNumeric</td>\n",
       "      <td>0.543351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Survived</td>\n",
       "      <td>TitleNumeric</td>\n",
       "      <td>0.364918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Survived</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.338481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Survived</td>\n",
       "      <td>CabinGoodNumeric</td>\n",
       "      <td>0.284435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Survived</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Survived</td>\n",
       "      <td>FareAdjusted</td>\n",
       "      <td>0.250635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1         Feature 2  Correlation Coefficient\n",
       "20  Survived        SexNumeric                 0.543351\n",
       "33  Survived      TitleNumeric                 0.364918\n",
       "39  Survived            Pclass                 0.338481\n",
       "48  Survived  CabinGoodNumeric                 0.284435\n",
       "57  Survived              Fare                 0.257307\n",
       "60  Survived      FareAdjusted                 0.250635"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train_corr = t_train_orig.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "t_train_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "groups = t_train_corr[(0.1 < t_train_corr[\"Correlation Coefficient\"]) & (t_train_corr[\"Correlation Coefficient\"] < .85)].groupby('Feature 1')\n",
    "groups.get_group('Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FareAdjusted</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SexNumeric</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title_Dr.</th>\n",
       "      <th>Title_Master.</th>\n",
       "      <th>Title_Miss.</th>\n",
       "      <th>Title_Mr.</th>\n",
       "      <th>Title_Mrs.</th>\n",
       "      <th>Title_Rev.</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>23.4500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>7.7500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FareAdjusted  Pclass  SexNumeric   Age  Title_Dr.  Title_Master.  \\\n",
       "0          7.2500       3           0  22.0          0              0   \n",
       "1         71.2833       1           1  38.0          0              0   \n",
       "2          7.9250       3           1  26.0          0              0   \n",
       "3         53.1000       1           1  35.0          0              0   \n",
       "4          8.0500       3           0  35.0          0              0   \n",
       "..            ...     ...         ...   ...        ...            ...   \n",
       "886       13.0000       2           0  27.0          0              0   \n",
       "887       30.0000       1           1  19.0          0              0   \n",
       "888       23.4500       3           1  24.0          0              0   \n",
       "889       30.0000       1           0  26.0          0              0   \n",
       "890        7.7500       3           0  32.0          0              0   \n",
       "\n",
       "     Title_Miss.  Title_Mr.  Title_Mrs.  Title_Rev.  Deck_A  Deck_B  Deck_C  \\\n",
       "0              0          1           0           0       0       0       0   \n",
       "1              0          0           1           0       0       0       1   \n",
       "2              1          0           0           0       0       0       0   \n",
       "3              0          0           1           0       0       0       1   \n",
       "4              0          1           0           0       0       0       0   \n",
       "..           ...        ...         ...         ...     ...     ...     ...   \n",
       "886            0          0           0           1       0       0       0   \n",
       "887            1          0           0           0       0       1       0   \n",
       "888            1          0           0           0       0       0       0   \n",
       "889            0          1           0           0       0       0       1   \n",
       "890            0          1           0           0       0       0       0   \n",
       "\n",
       "     Deck_D  Deck_E  Deck_F  Deck_G  Deck_U  \n",
       "0         0       0       0       0       1  \n",
       "1         0       0       0       0       0  \n",
       "2         0       0       0       0       1  \n",
       "3         0       0       0       0       0  \n",
       "4         0       0       0       0       1  \n",
       "..      ...     ...     ...     ...     ...  \n",
       "886       0       0       0       0       1  \n",
       "887       0       0       0       0       0  \n",
       "888       0       0       0       0       1  \n",
       "889       0       0       0       0       0  \n",
       "890       0       0       0       0       1  \n",
       "\n",
       "[891 rows x 18 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols_ohe = ['FareAdjusted', 'Pclass', 'SexNumeric', 'Title', 'Age', 'Deck']\n",
    "X_ohe = t_train[feature_cols_ohe]\n",
    "\n",
    "X_ohe = pd.concat([X_ohe,pd.get_dummies(X_ohe['Title'], prefix='Title')],axis=1).drop('Title', axis=1)\n",
    "X_ohe = pd.concat([X_ohe,pd.get_dummies(X_ohe['Deck'], prefix='Deck')],axis=1).drop('Deck', axis=1)\n",
    "\n",
    "# drop features that got a 0.0000 importance \n",
    "X_ohe = X_ohe.drop(['Title_Countess.', 'Deck_T', 'Title_Ms.', 'Title_Sir.', 'Title_Don.', 'Title_Capt.', \n",
    "                    'Title_Col.', 'Title_Mlle.', 'Title_Major.', 'Title_Lady.', 'Title_Jonkheer.', \n",
    "                    'Title_Mme.', 'Deck_T'] , axis=1)\n",
    "X_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply Random Forrest Classifier to the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X_re = X_ohe\n",
    "y_re = t_train.Survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_re, y_re, test_size=0.25, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100,\n",
    "                             min_samples_split=3, min_samples_leaf=3, max_depth=15,\n",
    "                             max_features=0.85, n_jobs=-1)\n",
    "\n",
    "cv_results = cross_validate(rfc, X_re,y_re, return_train_score=True, return_estimator=True, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit   Time:  [1.81674528 1.68478918 1.72295928 1.77509284 1.75710678]\n",
      "Score Time:  [0.11378288 0.11243391 0.11310673 0.11427212 0.11012197]\n",
      "\n",
      "Train Score: [0.9002809  0.91853933 0.89761571 0.90322581 0.90056022]\n",
      "Test Score:  [0.82681564 0.81005587 0.88764045 0.82022472 0.85310734]\n",
      "\n",
      "============\n",
      "               importance\n",
      "Title_Mr.        0.292942\n",
      "FareAdjusted     0.227083\n",
      "Age              0.155169\n",
      "Pclass           0.123908\n",
      "SexNumeric       0.118286\n",
      "Deck_U           0.026828\n",
      "Deck_E           0.011877\n",
      "Title_Master.    0.008571\n",
      "Title_Rev.       0.007066\n",
      "Title_Mrs.       0.006677\n",
      "Deck_C           0.005778\n",
      "Title_Miss.      0.004221\n",
      "Deck_B           0.004141\n",
      "Deck_D           0.002879\n",
      "Title_Dr.        0.002560\n",
      "Deck_A           0.002013\n",
      "Deck_F           0.000000\n",
      "Deck_G           0.000000\n",
      "============\n",
      "               importance\n",
      "Title_Mr.        0.278445\n",
      "FareAdjusted     0.234039\n",
      "Age              0.157411\n",
      "SexNumeric       0.119183\n",
      "Pclass           0.117375\n",
      "Deck_U           0.039119\n",
      "Title_Rev.       0.013501\n",
      "Title_Master.    0.009303\n",
      "Deck_E           0.007126\n",
      "Title_Miss.      0.006356\n",
      "Deck_B           0.004121\n",
      "Deck_C           0.003904\n",
      "Deck_D           0.003770\n",
      "Title_Mrs.       0.003216\n",
      "Deck_A           0.001289\n",
      "Title_Dr.        0.001165\n",
      "Deck_F           0.000677\n",
      "Deck_G           0.000000\n",
      "============\n",
      "               importance\n",
      "FareAdjusted     0.232610\n",
      "Title_Mr.        0.229084\n",
      "SexNumeric       0.200071\n",
      "Age              0.162524\n",
      "Pclass           0.096920\n",
      "Deck_U           0.029324\n",
      "Title_Rev.       0.013034\n",
      "Title_Master.    0.011393\n",
      "Deck_D           0.006941\n",
      "Deck_C           0.004243\n",
      "Title_Miss.      0.003327\n",
      "Deck_E           0.003181\n",
      "Title_Mrs.       0.002867\n",
      "Deck_B           0.001671\n",
      "Title_Dr.        0.001277\n",
      "Deck_A           0.001143\n",
      "Deck_F           0.000207\n",
      "Deck_G           0.000184\n",
      "============\n",
      "               importance\n",
      "SexNumeric       0.246861\n",
      "FareAdjusted     0.206138\n",
      "Title_Mr.        0.200245\n",
      "Age              0.172735\n",
      "Pclass           0.092533\n",
      "Deck_U           0.027616\n",
      "Title_Master.    0.013390\n",
      "Deck_E           0.008820\n",
      "Title_Mrs.       0.007842\n",
      "Deck_C           0.006264\n",
      "Title_Miss.      0.006039\n",
      "Title_Rev.       0.004603\n",
      "Title_Dr.        0.002522\n",
      "Deck_D           0.001944\n",
      "Deck_B           0.001417\n",
      "Deck_A           0.000481\n",
      "Deck_G           0.000344\n",
      "Deck_F           0.000206\n",
      "============\n",
      "               importance\n",
      "FareAdjusted     0.236047\n",
      "Title_Mr.        0.231312\n",
      "SexNumeric       0.194553\n",
      "Age              0.157249\n",
      "Pclass           0.106047\n",
      "Deck_U           0.025126\n",
      "Title_Rev.       0.007745\n",
      "Deck_D           0.006896\n",
      "Title_Mrs.       0.005939\n",
      "Deck_C           0.005683\n",
      "Title_Master.    0.005180\n",
      "Deck_E           0.005102\n",
      "Title_Miss.      0.004150\n",
      "Deck_A           0.003372\n",
      "Deck_B           0.002954\n",
      "Title_Dr.        0.002307\n",
      "Deck_F           0.000310\n",
      "Deck_G           0.000028\n"
     ]
    }
   ],
   "source": [
    "print(f'Fit   Time:  {cv_results[\"fit_time\"]}')\n",
    "print(f'Score Time:  {cv_results[\"score_time\"]}\\n')\n",
    "print(f'Train Score: {cv_results[\"train_score\"]}')\n",
    "print(f'Test Score:  {cv_results[\"test_score\"]}\\n')\n",
    "\n",
    "from IPython.lib.pretty import pretty\n",
    "\n",
    "estimators = list(cv_results['estimator'])\n",
    "\n",
    "for estimator in estimators:\n",
    "    print(\"============\")\n",
    "    print(pd.DataFrame(estimator.feature_importances_,\n",
    "                        index = X_re.columns,\n",
    "                        columns=['importance']).sort_values('importance',ascending=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=0.85,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=3,\n",
       "                                              min_samples_split=3,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': [10, 50, 100, 250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_cv = X_ohe\n",
    "y_cv = t_train.Survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cv, y_cv, test_size=0.20, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(min_samples_split=3, min_samples_leaf=3,\n",
    "                             max_features=0.85, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [1, 2, 4, 6, 8, 10, 15],\n",
    "    'n_estimators': [10, 50, 100, 250]}\n",
    "\n",
    "search = GridSearchCV(rfc, param_grid, cv=5)\n",
    "\n",
    "search.fit(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.120427</td>\n",
       "      <td>0.052114</td>\n",
       "      <td>0.109969</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>15</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 250}</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.846240</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.392598</td>\n",
       "      <td>0.071597</td>\n",
       "      <td>0.111798</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 250}</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.893258</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.842873</td>\n",
       "      <td>0.031672</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.274425</td>\n",
       "      <td>0.095976</td>\n",
       "      <td>0.113092</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.842873</td>\n",
       "      <td>0.028750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.175388</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.110422</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.842873</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.046369</td>\n",
       "      <td>0.118414</td>\n",
       "      <td>0.110960</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.893258</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.841751</td>\n",
       "      <td>0.032382</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.362281</td>\n",
       "      <td>0.128880</td>\n",
       "      <td>0.112637</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.841751</td>\n",
       "      <td>0.025390</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.188984</td>\n",
       "      <td>0.068119</td>\n",
       "      <td>0.111966</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 50}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.840629</td>\n",
       "      <td>0.031825</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.946124</td>\n",
       "      <td>0.058836</td>\n",
       "      <td>0.181375</td>\n",
       "      <td>0.138385</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.840629</td>\n",
       "      <td>0.030253</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.486188</td>\n",
       "      <td>0.160407</td>\n",
       "      <td>0.111920</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 250}</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.027830</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.478653</td>\n",
       "      <td>0.093497</td>\n",
       "      <td>0.113016</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 50}</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.188647</td>\n",
       "      <td>0.104150</td>\n",
       "      <td>0.111986</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 10}</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.025032</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.080282</td>\n",
       "      <td>0.076303</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.026537</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.886107</td>\n",
       "      <td>0.089746</td>\n",
       "      <td>0.113539</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 100}</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.026447</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.070035</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 10}</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.913160</td>\n",
       "      <td>0.178302</td>\n",
       "      <td>0.109598</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 10}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.053050</td>\n",
       "      <td>0.239499</td>\n",
       "      <td>0.113106</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 250}</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.829425</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.111241</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.015765</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.591125</td>\n",
       "      <td>0.056404</td>\n",
       "      <td>0.111443</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 10}</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.821696</td>\n",
       "      <td>0.146648</td>\n",
       "      <td>0.110981</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 50}</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.019626</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.244533</td>\n",
       "      <td>0.051781</td>\n",
       "      <td>0.110444</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 250}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.823793</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.728031</td>\n",
       "      <td>0.071209</td>\n",
       "      <td>0.112181</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.624435</td>\n",
       "      <td>0.049909</td>\n",
       "      <td>0.112283</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 10}</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.638233</td>\n",
       "      <td>0.043263</td>\n",
       "      <td>0.111327</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 50}</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.996133</td>\n",
       "      <td>0.069956</td>\n",
       "      <td>0.109347</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 250}</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.780022</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.524208</td>\n",
       "      <td>0.045331</td>\n",
       "      <td>0.111038</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 10}</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.887164</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>0.109650</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 250}</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.731462</td>\n",
       "      <td>0.031969</td>\n",
       "      <td>0.110042</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 100}</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.813918</td>\n",
       "      <td>0.081058</td>\n",
       "      <td>0.111759</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 100}</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.016941</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "27       2.120427      0.052114         0.109969        0.001866   \n",
       "23       2.392598      0.071597         0.111798        0.001374   \n",
       "22       2.274425      0.095976         0.113092        0.001524   \n",
       "18       2.175388      0.058118         0.110422        0.001814   \n",
       "25       2.046369      0.118414         0.110960        0.001641   \n",
       "21       2.362281      0.128880         0.112637        0.001973   \n",
       "17       2.188984      0.068119         0.111966        0.001592   \n",
       "26       1.946124      0.058836         0.181375        0.138385   \n",
       "19       2.486188      0.160407         0.111920        0.001652   \n",
       "13       2.478653      0.093497         0.113016        0.002884   \n",
       "16       2.188647      0.104150         0.111986        0.001845   \n",
       "20       2.080282      0.076303         0.111431        0.001249   \n",
       "14       2.886107      0.089746         0.113539        0.001638   \n",
       "24       1.878622      0.070035         0.111790        0.002355   \n",
       "12       1.913160      0.178302         0.109598        0.000886   \n",
       "15       3.053050      0.239499         0.113106        0.001669   \n",
       "10       1.829425      0.112885         0.111241        0.002114   \n",
       "8        1.591125      0.056404         0.111443        0.001687   \n",
       "9        1.821696      0.146648         0.110981        0.001797   \n",
       "11       2.244533      0.051781         0.110444        0.001499   \n",
       "5        1.728031      0.071209         0.112181        0.002165   \n",
       "4        1.624435      0.049909         0.112283        0.001525   \n",
       "1        1.638233      0.043263         0.111327        0.001498   \n",
       "7        1.996133      0.069956         0.109347        0.002352   \n",
       "0        1.524208      0.045331         0.111038        0.001953   \n",
       "3        1.887164      0.066950         0.109650        0.001302   \n",
       "2        1.731462      0.031969         0.110042        0.001648   \n",
       "6        1.813918      0.081058         0.111759        0.001717   \n",
       "\n",
       "   param_max_depth param_n_estimators                                  params  \\\n",
       "27              15                250  {'max_depth': 15, 'n_estimators': 250}   \n",
       "23              10                250  {'max_depth': 10, 'n_estimators': 250}   \n",
       "22              10                100  {'max_depth': 10, 'n_estimators': 100}   \n",
       "18               8                100   {'max_depth': 8, 'n_estimators': 100}   \n",
       "25              15                 50   {'max_depth': 15, 'n_estimators': 50}   \n",
       "21              10                 50   {'max_depth': 10, 'n_estimators': 50}   \n",
       "17               8                 50    {'max_depth': 8, 'n_estimators': 50}   \n",
       "26              15                100  {'max_depth': 15, 'n_estimators': 100}   \n",
       "19               8                250   {'max_depth': 8, 'n_estimators': 250}   \n",
       "13               6                 50    {'max_depth': 6, 'n_estimators': 50}   \n",
       "16               8                 10    {'max_depth': 8, 'n_estimators': 10}   \n",
       "20              10                 10   {'max_depth': 10, 'n_estimators': 10}   \n",
       "14               6                100   {'max_depth': 6, 'n_estimators': 100}   \n",
       "24              15                 10   {'max_depth': 15, 'n_estimators': 10}   \n",
       "12               6                 10    {'max_depth': 6, 'n_estimators': 10}   \n",
       "15               6                250   {'max_depth': 6, 'n_estimators': 250}   \n",
       "10               4                100   {'max_depth': 4, 'n_estimators': 100}   \n",
       "8                4                 10    {'max_depth': 4, 'n_estimators': 10}   \n",
       "9                4                 50    {'max_depth': 4, 'n_estimators': 50}   \n",
       "11               4                250   {'max_depth': 4, 'n_estimators': 250}   \n",
       "5                2                 50    {'max_depth': 2, 'n_estimators': 50}   \n",
       "4                2                 10    {'max_depth': 2, 'n_estimators': 10}   \n",
       "1                1                 50    {'max_depth': 1, 'n_estimators': 50}   \n",
       "7                2                250   {'max_depth': 2, 'n_estimators': 250}   \n",
       "0                1                 10    {'max_depth': 1, 'n_estimators': 10}   \n",
       "3                1                250   {'max_depth': 1, 'n_estimators': 250}   \n",
       "2                1                100   {'max_depth': 1, 'n_estimators': 100}   \n",
       "6                2                100   {'max_depth': 2, 'n_estimators': 100}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "27           0.843575           0.815642           0.887640   \n",
       "23           0.843575           0.810056           0.893258   \n",
       "22           0.843575           0.810056           0.887640   \n",
       "18           0.837989           0.815642           0.876404   \n",
       "25           0.826816           0.804469           0.893258   \n",
       "21           0.843575           0.810056           0.882022   \n",
       "17           0.826816           0.810056           0.882022   \n",
       "26           0.826816           0.810056           0.887640   \n",
       "19           0.832402           0.804469           0.876404   \n",
       "13           0.843575           0.804469           0.876404   \n",
       "16           0.837989           0.798883           0.859551   \n",
       "20           0.826816           0.804469           0.876404   \n",
       "14           0.837989           0.798883           0.865169   \n",
       "24           0.815642           0.826816           0.865169   \n",
       "12           0.826816           0.821229           0.842697   \n",
       "15           0.832402           0.798883           0.865169   \n",
       "10           0.837989           0.810056           0.837079   \n",
       "8            0.837989           0.810056           0.842697   \n",
       "9            0.837989           0.810056           0.842697   \n",
       "11           0.826816           0.810056           0.831461   \n",
       "5            0.759777           0.798883           0.792135   \n",
       "4            0.770950           0.798883           0.786517   \n",
       "1            0.782123           0.798883           0.786517   \n",
       "7            0.759777           0.798883           0.786517   \n",
       "0            0.782123           0.787709           0.786517   \n",
       "3            0.782123           0.787709           0.786517   \n",
       "2            0.782123           0.787709           0.786517   \n",
       "6            0.754190           0.798883           0.786517   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "27           0.820225           0.864407         0.846240        0.027068   \n",
       "23           0.808989           0.858757         0.842873        0.031672   \n",
       "22           0.814607           0.858757         0.842873        0.028750   \n",
       "18           0.814607           0.870056         0.842873        0.026168   \n",
       "25           0.820225           0.864407         0.841751        0.032382   \n",
       "21           0.820225           0.853107         0.841751        0.025390   \n",
       "17           0.808989           0.875706         0.840629        0.031825   \n",
       "26           0.814607           0.864407         0.840629        0.030253   \n",
       "19           0.814607           0.864407         0.838384        0.027830   \n",
       "13           0.808989           0.847458         0.836139        0.026631   \n",
       "16           0.808989           0.858757         0.832772        0.025032   \n",
       "20           0.808989           0.847458         0.832772        0.026537   \n",
       "14           0.803371           0.853107         0.831650        0.026447   \n",
       "24           0.803371           0.847458         0.831650        0.022136   \n",
       "12           0.808989           0.853107         0.830527        0.015610   \n",
       "15           0.797753           0.853107         0.829405        0.027500   \n",
       "10           0.808989           0.847458         0.828283        0.015765   \n",
       "8            0.792135           0.853107         0.827160        0.022569   \n",
       "9            0.797753           0.847458         0.827160        0.019626   \n",
       "11           0.803371           0.847458         0.823793        0.015686   \n",
       "5            0.780899           0.779661         0.782267        0.013351   \n",
       "4            0.769663           0.779661         0.781145        0.010800   \n",
       "1            0.752809           0.785311         0.781145        0.015265   \n",
       "7            0.775281           0.779661         0.780022        0.012913   \n",
       "0            0.752809           0.785311         0.778900        0.013169   \n",
       "3            0.752809           0.785311         0.778900        0.013169   \n",
       "2            0.752809           0.785311         0.778900        0.013169   \n",
       "6            0.758427           0.779661         0.775533        0.016941   \n",
       "\n",
       "    rank_test_score  \n",
       "27                1  \n",
       "23                2  \n",
       "22                2  \n",
       "18                2  \n",
       "25                5  \n",
       "21                5  \n",
       "17                7  \n",
       "26                7  \n",
       "19                9  \n",
       "13               10  \n",
       "16               11  \n",
       "20               11  \n",
       "14               13  \n",
       "24               13  \n",
       "12               15  \n",
       "15               16  \n",
       "10               17  \n",
       "8                18  \n",
       "9                18  \n",
       "11               20  \n",
       "5                21  \n",
       "4                22  \n",
       "1                22  \n",
       "7                24  \n",
       "0                25  \n",
       "3                25  \n",
       "2                25  \n",
       "6                28  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_resultsDF = pd.DataFrame(search.cv_results_)\n",
    "cv_resultsDF.sort_values(by=['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilty (count = 891\n",
      "[[0.93191471 0.06808529]\n",
      " [0.11022188 0.88977812]\n",
      " [0.40116983 0.59883017]\n",
      " ...\n",
      " [0.40131613 0.59868387]\n",
      " [0.64606079 0.35393921]\n",
      " [0.93191595 0.06808405]]\n",
      "\n",
      "score: 0.8385650224215246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feature_cols = ['FareAdjusted', 'Pclass', 'SexNumeric', 'TitleNumeric']\n",
    "\n",
    "X_lr = t_train[feature_cols]\n",
    "y_lr = t_train.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lr, y_lr, test_size=0.25, random_state=1) # 70% training and 30% test\n",
    "\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial').fit(X_train, y_train)\n",
    "prob = lr.predict_proba(X_lr)\n",
    "\n",
    "print(f'probabilty (count = {len(prob)}\\n{prob}\\n')\n",
    "print(f'score: {clf.score(X_test, y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K-Nearest Neighbors\n",
    "because.. why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  10]\n",
      " [ 37  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       128\n",
      "           1       0.85      0.61      0.71        95\n",
      "\n",
      "    accuracy                           0.79       223\n",
      "   macro avg       0.81      0.77      0.77       223\n",
      "weighted avg       0.80      0.79      0.78       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
